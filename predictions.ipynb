{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Player     G  PTS/36  TRB/36  AST/36  STL/36  BLK/36  TOV/36   \n",
      "0      LeBron James  0.62    0.75    0.51    0.55    0.44    0.26    0.27  \\\n",
      "1      Kevin Durant  0.94    0.84    0.48    0.22    0.28    0.35    0.73   \n",
      "2   Carmelo Anthony  0.06    1.00    0.40    0.00    0.00    0.13    0.00   \n",
      "3        Chris Paul  0.25    0.00    0.08    1.00    1.00    0.00    0.00   \n",
      "4       Kobe Bryant  0.75    0.75    0.22    0.39    0.28    0.06    0.91   \n",
      "..              ...   ...     ...     ...     ...     ...     ...     ...   \n",
      "5      Jayson Tatum  1.00    0.66    0.32    0.00    0.08    0.23    0.23   \n",
      "6         Ja Morant  0.00    0.83    0.14    0.39    0.33    0.08    0.59   \n",
      "7     Stephen Curry  0.37    0.63    0.06    0.30    0.42    0.08    0.41   \n",
      "8        Chris Paul  0.42    0.00    0.00    1.00    1.00    0.00    0.09   \n",
      "9     DeMar DeRozan  1.00    0.70    0.04    0.07    0.00    0.00    0.00   \n",
      "\n",
      "     TS%   PER  ...  On_Off   TWR    VPS  T_PTS  T_TRB  T_AST  T_STL  T_BLK   \n",
      "0   0.94  1.00  ...    1.00  1.00  0.998   0.78   0.84   0.75   0.66   0.34  \\\n",
      "1   1.00  0.62  ...    0.57  0.72  0.632   1.00   0.91   0.40   0.55   0.56   \n",
      "2   0.24  0.22  ...    0.37  0.44  0.393   0.67   0.54   0.00   0.02   0.15   \n",
      "3   0.54  0.40  ...    0.54  0.53  0.239   0.00   0.13   1.00   1.00   0.02   \n",
      "4   0.33  0.01  ...    0.34  0.00  0.152   0.87   0.48   0.59   0.47   0.11   \n",
      "..   ...   ...  ...     ...   ...    ...    ...    ...    ...    ...    ...   \n",
      "5   0.08  0.08  ...    0.86  0.29  0.043   0.94   0.44   0.12   0.16   0.37   \n",
      "6   0.04  0.30  ...    0.00  0.57  0.010   0.52   0.06   0.24   0.00   0.03   \n",
      "7   0.33  0.05  ...    0.65  0.39  0.004   0.58   0.07   0.29   0.35   0.04   \n",
      "8   0.11  0.00  ...    0.39  1.00  0.002   0.00   0.00   1.00   1.00   0.00   \n",
      "9   0.21  0.19  ...    0.38  0.00  0.001   1.00   0.15   0.22   0.04   0.05   \n",
      "\n",
      "    T_TOV  T_WS  \n",
      "0    0.53  1.00  \n",
      "1    0.90  0.96  \n",
      "2    0.19  0.11  \n",
      "3    0.08  0.51  \n",
      "4    0.95  0.24  \n",
      "..    ...   ...  \n",
      "5    0.46  0.34  \n",
      "6    0.31  0.00  \n",
      "7    0.38  0.15  \n",
      "8    0.00  0.32  \n",
      "9    0.20  0.25  \n",
      "\n",
      "[100 rows x 23 columns]\n",
      "Performance with Random Forest and All:\n",
      "MSE: 0.043\n",
      "R-squared: 0.696\n",
      "Performance with Random Forest and All_without_G:\n",
      "MSE: 0.042\n",
      "R-squared: 0.703\n",
      "Performance with Random Forest and Per36_with_AS:\n",
      "MSE: 0.043\n",
      "R-squared: 0.702\n",
      "Performance with Random Forest and Totals_with_AS:\n",
      "MSE: 0.039\n",
      "R-squared: 0.727\n",
      "Performance with Random Forest and Per36:\n",
      "MSE: 0.080\n",
      "R-squared: 0.438\n",
      "Performance with Random Forest and AS:\n",
      "MSE: 0.031\n",
      "R-squared: 0.779\n",
      "\n",
      "Performance with Gradient Boosting and All:\n",
      "MSE: 0.035\n",
      "R-squared: 0.752\n",
      "Performance with Gradient Boosting and All_without_G:\n",
      "MSE: 0.033\n",
      "R-squared: 0.772\n",
      "Performance with Gradient Boosting and Per36_with_AS:\n",
      "MSE: 0.075\n",
      "R-squared: 0.471\n",
      "Performance with Gradient Boosting and Totals_with_AS:\n",
      "MSE: 0.025\n",
      "R-squared: 0.824\n",
      "Performance with Gradient Boosting and Per36:\n",
      "MSE: 0.146\n",
      "R-squared: -0.027\n",
      "Performance with Gradient Boosting and AS:\n",
      "MSE: 0.025\n",
      "R-squared: 0.822\n",
      "\n",
      "Performance with XGBoost and All:\n",
      "MSE: 0.031\n",
      "R-squared: 0.782\n",
      "Performance with XGBoost and All_without_G:\n",
      "MSE: 0.033\n",
      "R-squared: 0.767\n",
      "Performance with XGBoost and Per36_with_AS:\n",
      "MSE: 0.051\n",
      "R-squared: 0.640\n",
      "Performance with XGBoost and Totals_with_AS:\n",
      "MSE: 0.032\n",
      "R-squared: 0.776\n",
      "Performance with XGBoost and Per36:\n",
      "MSE: 0.102\n",
      "R-squared: 0.286\n",
      "Performance with XGBoost and AS:\n",
      "MSE: 0.033\n",
      "R-squared: 0.772\n",
      "\n",
      "Performance with Linear Regression and All:\n",
      "MSE: 0.058\n",
      "R-squared: 0.592\n",
      "Performance with Linear Regression and All_without_G:\n",
      "MSE: 0.053\n",
      "R-squared: 0.628\n",
      "Performance with Linear Regression and Per36_with_AS:\n",
      "MSE: 0.030\n",
      "R-squared: 0.791\n",
      "Performance with Linear Regression and Totals_with_AS:\n",
      "MSE: 0.029\n",
      "R-squared: 0.800\n",
      "Performance with Linear Regression and Per36:\n",
      "MSE: 0.049\n",
      "R-squared: 0.657\n",
      "Performance with Linear Regression and AS:\n",
      "MSE: 0.036\n",
      "R-squared: 0.750\n",
      "\n",
      "Performance with Lasso and All:\n",
      "MSE: 0.057\n",
      "R-squared: 0.603\n",
      "Performance with Lasso and All_without_G:\n",
      "MSE: 0.057\n",
      "R-squared: 0.603\n",
      "Performance with Lasso and Per36_with_AS:\n",
      "MSE: 0.053\n",
      "R-squared: 0.630\n",
      "Performance with Lasso and Totals_with_AS:\n",
      "MSE: 0.056\n",
      "R-squared: 0.610\n",
      "Performance with Lasso and Per36:\n",
      "MSE: 0.087\n",
      "R-squared: 0.390\n",
      "Performance with Lasso and AS:\n",
      "MSE: 0.058\n",
      "R-squared: 0.591\n",
      "\n",
      "Performance with Ridge Regression and All:\n",
      "MSE: 0.043\n",
      "R-squared: 0.695\n",
      "Performance with Ridge Regression and All_without_G:\n",
      "MSE: 0.040\n",
      "R-squared: 0.723\n",
      "Performance with Ridge Regression and Per36_with_AS:\n",
      "MSE: 0.030\n",
      "R-squared: 0.789\n",
      "Performance with Ridge Regression and Totals_with_AS:\n",
      "MSE: 0.028\n",
      "R-squared: 0.801\n",
      "Performance with Ridge Regression and Per36:\n",
      "MSE: 0.050\n",
      "R-squared: 0.652\n",
      "Performance with Ridge Regression and AS:\n",
      "MSE: 0.037\n",
      "R-squared: 0.743\n",
      "\n",
      "Performance with Elastic Net and All:\n",
      "MSE: 0.162\n",
      "R-squared: -0.134\n",
      "Performance with Elastic Net and All_without_G:\n",
      "MSE: 0.162\n",
      "R-squared: -0.134\n",
      "Performance with Elastic Net and Per36_with_AS:\n",
      "MSE: 0.162\n",
      "R-squared: -0.136\n",
      "Performance with Elastic Net and Totals_with_AS:\n",
      "MSE: 0.162\n",
      "R-squared: -0.134\n",
      "Performance with Elastic Net and Per36:\n",
      "MSE: 0.186\n",
      "R-squared: -0.305\n",
      "Performance with Elastic Net and AS:\n",
      "MSE: 0.162\n",
      "R-squared: -0.134\n",
      "\n",
      "Performance with k-NN and All:\n",
      "MSE: 0.037\n",
      "R-squared: 0.738\n",
      "Performance with k-NN and All_without_G:\n",
      "MSE: 0.037\n",
      "R-squared: 0.739\n",
      "Performance with k-NN and Per36_with_AS:\n",
      "MSE: 0.039\n",
      "R-squared: 0.726\n",
      "Performance with k-NN and Totals_with_AS:\n",
      "MSE: 0.033\n",
      "R-squared: 0.770\n",
      "Performance with k-NN and Per36:\n",
      "MSE: 0.099\n",
      "R-squared: 0.306\n",
      "Performance with k-NN and AS:\n",
      "MSE: 0.046\n",
      "R-squared: 0.679\n",
      "\n",
      "Performance with SVR and All:\n",
      "MSE: 0.035\n",
      "R-squared: 0.754\n",
      "Performance with SVR and All_without_G:\n",
      "MSE: 0.037\n",
      "R-squared: 0.741\n",
      "Performance with SVR and Per36_with_AS:\n",
      "MSE: 0.036\n",
      "R-squared: 0.746\n",
      "Performance with SVR and Totals_with_AS:\n",
      "MSE: 0.032\n",
      "R-squared: 0.778\n",
      "Performance with SVR and Per36:\n",
      "MSE: 0.062\n",
      "R-squared: 0.565\n",
      "Performance with SVR and AS:\n",
      "MSE: 0.039\n",
      "R-squared: 0.725\n",
      "\n",
      "Predicted MVP ranking with SVR and AS:\n",
      "1. Nikola Jokić\n",
      "2. Joel Embiid\n",
      "3. Giannis Antetokounmpo\n",
      "4. Jimmy Butler\n",
      "5. Luka Dončić\n",
      "6. Jayson Tatum\n",
      "7. James Harden\n",
      "8. Domantas Sabonis\n",
      "9. Shai Gilgeous-Alexander\n",
      "10. Damian Lillard\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikes\\AppData\\Local\\Temp\\ipykernel_17800\\3723790100.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n",
      "C:\\Users\\mikes\\AppData\\Local\\Temp\\ipykernel_17800\\3723790100.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n",
      "C:\\Users\\mikes\\AppData\\Local\\Temp\\ipykernel_17800\\3723790100.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n",
      "C:\\Users\\mikes\\AppData\\Local\\Temp\\ipykernel_17800\\3723790100.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n",
      "C:\\Users\\mikes\\AppData\\Local\\Temp\\ipykernel_17800\\3723790100.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n",
      "C:\\Users\\mikes\\AppData\\Local\\Temp\\ipykernel_17800\\3723790100.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n",
      "C:\\Users\\mikes\\AppData\\Local\\Temp\\ipykernel_17800\\3723790100.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n",
      "C:\\Users\\mikes\\AppData\\Local\\Temp\\ipykernel_17800\\3723790100.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n",
      "C:\\Users\\mikes\\AppData\\Local\\Temp\\ipykernel_17800\\3723790100.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Random Forest_All</th>\n",
       "      <th>Random Forest_All_without_G</th>\n",
       "      <th>Random Forest_Per36_with_AS</th>\n",
       "      <th>Random Forest_Totals_with_AS</th>\n",
       "      <th>Random Forest_Per36</th>\n",
       "      <th>Random Forest_AS</th>\n",
       "      <th>Gradient Boosting_All</th>\n",
       "      <th>Gradient Boosting_All_without_G</th>\n",
       "      <th>Gradient Boosting_Per36_with_AS</th>\n",
       "      <th>...</th>\n",
       "      <th>k-NN_Per36_with_AS_rank</th>\n",
       "      <th>k-NN_Totals_with_AS_rank</th>\n",
       "      <th>k-NN_Per36_rank</th>\n",
       "      <th>k-NN_AS_rank</th>\n",
       "      <th>SVR_All_rank</th>\n",
       "      <th>SVR_All_without_G_rank</th>\n",
       "      <th>SVR_Per36_with_AS_rank</th>\n",
       "      <th>SVR_Totals_with_AS_rank</th>\n",
       "      <th>SVR_Per36_rank</th>\n",
       "      <th>SVR_AS_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nikola Jokić</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.925</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.647</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.358</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jayson Tatum</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.047</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Domantas Sabonis</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.049</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Luka Dončić</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.091</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.161</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shai Gilgeous-Alexander</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.022</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.046</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Player  Random Forest_All  Random Forest_All_without_G   \n",
       "0             Nikola Jokić              0.736                        0.744  \\\n",
       "1              Joel Embiid              0.526                        0.517   \n",
       "2    Giannis Antetokounmpo              0.328                        0.323   \n",
       "3             Jayson Tatum              0.048                        0.044   \n",
       "4             James Harden              0.030                        0.030   \n",
       "5         Domantas Sabonis              0.123                        0.144   \n",
       "6              Luka Dončić              0.202                        0.212   \n",
       "7             Jimmy Butler              0.131                        0.123   \n",
       "8  Shai Gilgeous-Alexander              0.080                        0.079   \n",
       "9           Damian Lillard              0.056                        0.059   \n",
       "\n",
       "   Random Forest_Per36_with_AS  Random Forest_Totals_with_AS   \n",
       "0                        0.755                         0.768  \\\n",
       "1                        0.534                         0.492   \n",
       "2                        0.348                         0.169   \n",
       "3                        0.054                         0.107   \n",
       "4                        0.027                         0.039   \n",
       "5                        0.050                         0.147   \n",
       "6                        0.215                         0.214   \n",
       "7                        0.109                         0.143   \n",
       "8                        0.086                         0.064   \n",
       "9                        0.067                         0.058   \n",
       "\n",
       "   Random Forest_Per36  Random Forest_AS  Gradient Boosting_All   \n",
       "0                0.598             0.780                  0.873  \\\n",
       "1                0.576             0.440                  0.630   \n",
       "2                0.454             0.140                  0.443   \n",
       "3                0.078             0.154                  0.078   \n",
       "4                0.133             0.040                  0.015   \n",
       "5                0.145             0.147                  0.082   \n",
       "6                0.281             0.180                  0.093   \n",
       "7                0.113             0.169                  0.082   \n",
       "8                0.268             0.062                  0.037   \n",
       "9                0.144             0.038                  0.070   \n",
       "\n",
       "   Gradient Boosting_All_without_G  Gradient Boosting_Per36_with_AS  ...   \n",
       "0                            0.878                            0.925  ...  \\\n",
       "1                            0.608                            0.647  ...   \n",
       "2                            0.370                            0.358  ...   \n",
       "3                            0.087                            0.047  ...   \n",
       "4                            0.023                            0.012  ...   \n",
       "5                            0.156                            0.049  ...   \n",
       "6                            0.123                            0.091  ...   \n",
       "7                            0.163                            0.161  ...   \n",
       "8                            0.016                            0.022  ...   \n",
       "9                            0.071                            0.046  ...   \n",
       "\n",
       "   k-NN_Per36_with_AS_rank  k-NN_Totals_with_AS_rank  k-NN_Per36_rank   \n",
       "0                      1.0                       1.0              1.0  \\\n",
       "1                      2.0                       2.0              2.0   \n",
       "2                      3.0                       3.0              4.0   \n",
       "3                      7.0                       6.0              6.0   \n",
       "4                     10.0                      10.0              5.0   \n",
       "5                      8.0                       4.5              9.0   \n",
       "6                      5.0                       7.0              8.0   \n",
       "7                      4.0                       4.5              7.0   \n",
       "8                      6.0                       8.0              3.0   \n",
       "9                      9.0                       9.0             10.0   \n",
       "\n",
       "   k-NN_AS_rank  SVR_All_rank  SVR_All_without_G_rank  SVR_Per36_with_AS_rank   \n",
       "0           1.0           1.0                     1.0                     1.0  \\\n",
       "1           2.0           2.0                     2.0                     2.0   \n",
       "2           5.0           3.0                     3.0                     3.0   \n",
       "3           4.0           7.0                     6.0                     9.0   \n",
       "4           7.0           8.0                     8.0                     8.0   \n",
       "5           8.0          10.0                     9.0                    10.0   \n",
       "6           3.0           6.0                     7.0                     5.0   \n",
       "7           6.0           4.0                     4.0                     4.0   \n",
       "8           9.0           5.0                     5.0                     7.0   \n",
       "9          10.0           9.0                    10.0                     6.0   \n",
       "\n",
       "   SVR_Totals_with_AS_rank  SVR_Per36_rank  SVR_AS_rank  \n",
       "0                      1.0             1.0          1.0  \n",
       "1                      2.0             2.0          2.0  \n",
       "2                      3.0             3.0          3.0  \n",
       "3                      5.0             5.0          6.0  \n",
       "4                      9.0             4.0          7.0  \n",
       "5                      8.0             9.0          8.0  \n",
       "6                      7.0             6.0          5.0  \n",
       "7                      4.0             8.0          4.0  \n",
       "8                      6.0             7.0          9.0  \n",
       "9                     10.0            10.0         10.0  \n",
       "\n",
       "[10 rows x 109 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "# Define the columns to normalize\n",
    "cols_to_normalize = ['G', 'PTS/36', 'T_PTS', 'TRB/36', 'T_TRB', 'AST/36', 'T_AST', 'STL/36', 'T_STL', 'BLK/36', 'T_BLK', 'TOV/36', 'T_TOV', 'TS%', 'PER', 'WS/36', 'T_WS', 'BPM', 'VORP', 'On_Off', 'TWR']\n",
    "\n",
    "for year in range(2013, 2023):\n",
    "    file_name = f\"mvp{year}.csv\"\n",
    "    df_name = f\"df_{year}\"\n",
    "    dfs[df_name] = pd.read_csv(file_name)\n",
    "\n",
    "    # Read in the corresponding totals file \n",
    "    totals_file_name = f\"mvp{year}totals.csv\"\n",
    "    totals_df = pd.read_csv(totals_file_name)\n",
    "    \n",
    "    # Merge the two dataframes on the \"Player\" column\n",
    "    dfs[df_name] = pd.merge(dfs[df_name], totals_df, on=\"Player\")\n",
    "    \n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Normalize the selected columns\n",
    "    dfs[df_name][cols_to_normalize] = scaler.fit_transform(dfs[df_name][cols_to_normalize])\n",
    "    dfs[df_name][cols_to_normalize] = dfs[df_name][cols_to_normalize].apply(lambda x: round(x, 2))\n",
    "    \n",
    "# Read in the CSV file \n",
    "mvp_candidates = pd.read_csv(\"mvp_candidates.csv\")\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the selected columns\n",
    "mvp_candidates[cols_to_normalize] = scaler.fit_transform(mvp_candidates[cols_to_normalize])\n",
    "mvp_candidates[cols_to_normalize] = mvp_candidates[cols_to_normalize].apply(lambda x: round(x, 2))\n",
    "\n",
    "# Concatenate all the previous years' dataframes\n",
    "previous_years = pd.concat(dfs.values())\n",
    "print(previous_years)\n",
    "\n",
    "# Define the list of features and their names\n",
    "features_dict = { 'All': ['G', 'PTS/36', 'T_PTS', 'TRB/36', 'T_TRB', 'AST/36', 'T_AST', 'STL/36', 'T_STL', 'BLK/36', 'T_BLK', 'TOV/36', 'T_TOV', 'TS%', 'PER', 'WS/36', 'T_WS', 'BPM', 'VORP', 'On_Off', 'TWR'],\n",
    "                 'All_without_G': ['PTS/36', 'T_PTS', 'TRB/36', 'T_TRB', 'AST/36', 'T_AST', 'STL/36', 'T_STL', 'BLK/36', 'T_BLK', 'TOV/36', 'T_TOV', 'TS%', 'PER', 'WS/36', 'T_WS', 'BPM', 'VORP', 'On_Off', 'TWR'],\n",
    "                 'Per36_with_AS': ['G', 'PTS/36', 'TRB/36', 'AST/36', 'STL/36', 'BLK/36', 'TOV/36', 'TS%', 'PER', 'WS/36', 'BPM', 'VORP', 'On_Off', 'TWR'],\n",
    "                 'Totals_with_AS': ['T_PTS', 'T_TRB', 'T_AST', 'T_STL', 'T_BLK', 'T_TOV', 'TS%', 'PER', 'T_WS', 'BPM', 'VORP', 'On_Off', 'TWR'],\n",
    "                 'Per36': ['G', 'PTS/36', 'TRB/36', 'AST/36', 'STL/36', 'BLK/36', 'TOV/36', 'TS%', 'TWR'],\n",
    "                 'AS': ['TS%', 'PER', 'T_WS', 'BPM', 'VORP', 'On_Off', 'TWR'] } \n",
    "\n",
    "# Define the list of models to run\n",
    "# Define the list of models\n",
    "models_dict = { 'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "               'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42), \n",
    "               'XGBoost': XGBRegressor(n_estimators=100, max_depth=5, random_state=42), \n",
    "               'Linear Regression': LinearRegression(), \n",
    "               'Lasso': Lasso(alpha=0.01, max_iter=10000, random_state=42), \n",
    "               'Ridge Regression': Ridge(alpha=0.1, random_state=42), \n",
    "               'Elastic Net': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42), \n",
    "               'k-NN': KNeighborsRegressor(n_neighbors=5), \n",
    "               'SVR': SVR(kernel='rbf', C=1, gamma='scale') } \n",
    "\n",
    "# Define an empty dataframe to store the predictions\n",
    "pred_df = pd.DataFrame({'Player': mvp_candidates['Player']})\n",
    "\n",
    "# Train and predict using each model\n",
    "for name, model in models_dict.items(): \n",
    "    for features_name, features in features_dict.items(): \n",
    "        # Split the data into training and testing sets \n",
    "        X_train, X_test, y_train, y_test = train_test_split(previous_years[features], previous_years[\"VPS\"], test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Train the model \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the mvp_candidates dataframe\n",
    "        predictions = model.predict(mvp_candidates[features])\n",
    "        pred_df[f\"{name}_{features_name}\"] = predictions.round(3) \n",
    "        \n",
    "        # Compute the mean squared error and R-squared \n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Print the performance metrics\n",
    "        print(f\"Performance with {name} and {features_name}:\")\n",
    "        print(f\"MSE: {mse:.3f}\")\n",
    "        print(f\"R-squared: {r2:.3f}\")\n",
    "    print()\n",
    "        \n",
    "# Sort the candidates by predicted voting score for each list of features and each model\n",
    "for name in models_dict.keys():\n",
    "    for features_name in features_dict.keys():\n",
    "        pred_df[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}'].rank(ascending=False)\n",
    "        mvp_candidates[f'{name}_{features_name}_rank'] = pred_df[f'{name}_{features_name}_rank']\n",
    "        mvp_candidates.sort_values(by=f\"{name}_{features_name}_rank\", ascending=True, inplace=True)\n",
    "        \n",
    "# Print the predicted ranking for each list of features and each model\n",
    "print(f\"Predicted MVP ranking with {name} and {features_name}:\")\n",
    "for j, player in enumerate(mvp_candidates[\"Player\"]):\n",
    "    print(f\"{j+1}. {player}\")\n",
    "print() \n",
    "\n",
    "pred_df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
